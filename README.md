# NLP Independent Study: Semantic Similarity Analysis of GPT Outputs (Profiles)

This project compares **text answers generated by different GPT “profiles”** and measures **how similar the answers are** using **sentence embeddings** and **cosine similarity**.

The core idea is simple:
- You ask the **same set of questions/prompts**.
- Each profile (P1, P2, P3) generates an answer.
- We clean the text, split it into sentences, convert sentences into embeddings (vectors), and then compare sentences using cosine similarity.
- The final output is a **similarity score matrix per question**, so you can quickly see where two profiles are similar and where they are different.

---

## What you will see in the output

For each question:
- Rows = sentences from Profile A  
- Columns = sentences from Profile B  
- Each cell = similarity score (0 to 1)
  - Closer to **1** means “very similar meaning”
  - Closer to **0** means “not similar”

Example (score matrix view):
![Similarity matrix dataframe](NLP+Pics/pic_7.png)

---

## Why this project matters

When you have multiple GPT outputs for the same prompt (different profiles / settings / styles), it’s hard to manually check:
- Are the profiles giving the same answer?
- Which sentences match strongly?
- Which questions have the highest overlap?
- Where do the profiles differ in content?

This project gives a measurable, repeatable way to compare them.

---

## Data input (Excel format)

The notebooks load one Excel file that contains **three sheets**:
- `p1` → Profile 1 answers  
- `p2` → Profile 2 answers  
- `p3` → Profile 3 answers  

Each sheet should have:
- A question/prompt column (example: `PROMPT/QUESTION`)
- An answer column (example: `ANSWER`)

After stopword removal, the notebook also creates a helpful column:
- `FILTERED_WORDS` (cleaned words for analysis)

Example view of the dataframe:
![Dataframe with filtered words](NLP+Pics/pic_1.png)

> Note: In your notebook, the Excel file path is a local Windows path. Update it to your own path when you run it.

---

## Tech stack used

- **Python**
- **pandas / numpy** for data handling
- **spaCy** for stopword removal
- **sentence-transformers (SBERT)** for embeddings (`paraphrase-MiniLM-L6-v2`)
- **cosine similarity** for comparison
- **Excel export** for final results

---

## Step-by-step project workflow (start to end)

### Step 1: Prepare answers (Profiles P1, P2, P3)
- You load answers from Excel sheets.
- Each row is one question’s answer.

### Step 2: Text cleaning
The cleaning step removes things that add noise, like:
- new lines
- extra punctuation
- numbers

This helps the model focus on meaning.

### Step 3: Stopword removal (spaCy)
Stopwords are common words like **“the”, “is”, “and”** that usually don’t add meaning.

After this step, you get cleaner text in `FILTERED_WORDS`.

![Filtered words column](NLP+Pics/pic_1.png)

### Step 4: Split answers into sentences
Each answer is split into sentences so you can compare sentence-by-sentence (not just whole paragraphs).

Example (Profile 1 sentences list):
![Sentence split result](NLP+Pics/pic_3.png)

The logic used to split answers:
![Sentence splitting code output](NLP+Pics/pic_2.png)

### Step 5: Create embeddings using SBERT
You use the model: **paraphrase-MiniLM-L6-v2**.

Each sentence becomes an embedding vector.

![Embedding calculation](NLP+Pics/pic_4.png)

### Step 6: Build similarity matrix (cosine similarity)
For each question:
- Compare every sentence from Profile A with every sentence from Profile B.
- Store the cosine similarity scores in a matrix.

Printed matrix example:
![Printed similarity matrix](NLP+Pics/pic_5.png)

### Step 7: Make sentence-pair matrix (optional but useful)
To help with analysis, you also create a matrix of combined sentence pairs like:
- (P1) sentence i + (P2) sentence j

This makes it easy to inspect what matched.

![Sentence-pair matrix](NLP+Pics/pic_6.png)

### Step 8: Focus on strong matches with a threshold (example: > 0.75)
To highlight only the strongest matches, you filter the similarity matrix using a threshold.
- Example threshold used: **0.75**

![Filtered high similarity pairs](NLP+Pics/pic_8.png)

### Step 9: Summary stats (to understand the matrix)
You compute descriptive stats to understand score distribution:
- mean, std, min, max, quartiles

Column-wise stats:
![Column-wise stats](NLP+Pics/pic_9.png)

Row-wise stats:
![Row-wise stats](NLP+Pics/pic_10.png)

### Step 10: Matching words between similar sentences (extra analysis)
After finding high similarity pairs, you also extract **common words** between the two sentences.
This helps explain *why* two sentences look similar.

![Same words logic and output](NLP+Pics/pic_11.png)

---

## Extra experiments (from notebook)

### A) Paraphrase mining (find best paraphrase pairs)
This finds the top sentence pairs that are paraphrases (very similar meaning).

![Paraphrase mining](NLP+Pics/pic_12.png)

### B) Semantic search (search best matching sentence from a corpus)
This shows how SBERT can match a query to the most relevant sentence.

![Semantic search](NLP+Pics/pic_13.png)

---

## Output files (what you generate)

After running the notebooks, you can generate Excel files like:
- `p1&p2_similarity_score_final.xlsx`
- `p1&p3_similarity_score_final.xlsx`
- `p2&p3_similarity_score_final.xlsx`

Each Excel file contains multiple sheets (Q1, Q2, Q3, …), where each sheet is the similarity matrix for that question.

---

## How to run this project

### 1) Setup (Python environment)
Use Python 3.8+.

Install packages:
```bash
pip install pandas numpy spacy sentence-transformers openpyxl
python -m spacy download en_core_web_sm
